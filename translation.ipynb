{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"translation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Si5Esg_Cd_IP","executionInfo":{"status":"ok","timestamp":1625579024484,"user_tz":-330,"elapsed":19551,"user":{"displayName":"Chinta Snehith","photoUrl":"","userId":"09225997105087015766"}},"outputId":"a3f6599a-b664-4085-9e9b-37b569150cb7"},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C4fwZhOTeQSp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625579047933,"user_tz":-330,"elapsed":19846,"user":{"displayName":"Chinta Snehith","photoUrl":"","userId":"09225997105087015766"}},"outputId":"45b849f2-fb76-4c62-df2b-180f1411c7d9"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","\n","! pip install datasets transformers sacrebleu\n","! pip install sentencepiece\n","\n","from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n","from transformers import AutoTokenizer\n","\n","from transformers import pipeline\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/27/9c91ddee87b06d2de12f134c5171a49890427e398389f07f6463485723c3/datasets-1.9.0-py3-none-any.whl (262kB)\n","\u001b[K     |████████████████████████████████| 266kB 23.5MB/s \n","\u001b[?25hCollecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 35.7MB/s \n","\u001b[?25hCollecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Collecting huggingface-hub<0.1.0\n","  Downloading https://files.pythonhosted.org/packages/35/03/071adc023c0a7e540cf4652fa9cad13ab32e6ae469bf0cc0262045244812/huggingface_hub-0.0.13-py3-none-any.whl\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Collecting fsspec>=2021.05.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3a/666e63625a19883ae8e1674099e631f9737bd5478c4790e5ad49c5ac5261/fsspec-2021.6.1-py3-none-any.whl (115kB)\n","\u001b[K     |████████████████████████████████| 122kB 50.0MB/s \n","\u001b[?25hCollecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 49.6MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.5.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 39.2MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 37.6MB/s \n","\u001b[?25hCollecting portalocker==2.0.0\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","\u001b[31mERROR: transformers 4.8.2 has requirement huggingface-hub==0.0.12, but you'll have huggingface-hub 0.0.13 which is incompatible.\u001b[0m\n","Installing collected packages: huggingface-hub, fsspec, xxhash, datasets, sacremoses, tokenizers, transformers, portalocker, sacrebleu\n","Successfully installed datasets-1.9.0 fsspec-2021.6.1 huggingface-hub-0.0.13 portalocker-2.0.0 sacrebleu-1.5.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2 xxhash-2.0.2\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 28.1MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_bQcobEKyDXy","executionInfo":{"status":"ok","timestamp":1625579070058,"user_tz":-330,"elapsed":20857,"user":{"displayName":"Chinta Snehith","photoUrl":"","userId":"09225997105087015766"}}},"source":["translator_tr_en = pipeline(\"translation\",model=\"/content/drive/MyDrive/News article summarizer/Tr_En\")\n","translator_ru_en = pipeline(\"translation\",model=\"/content/drive/MyDrive/News article summarizer/Ru_En\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ob-dDHNWLwW-","executionInfo":{"status":"ok","timestamp":1625579255612,"user_tz":-330,"elapsed":362,"user":{"displayName":"Chinta Snehith","photoUrl":"","userId":"09225997105087015766"}}},"source":["def split_string(text, sep=\" \"):\n","    words = text.split()\n","    res, part, others = [], words[0], words[1:]\n","    for word in others:\n","        if len(sep)+len(word) > 512-len(part):\n","            res.append(part)\n","            part = word\n","        else:\n","            part += sep+word\n","    if part:\n","        res.append(part)\n","    return res"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"XF23HOZETRnJ"},"source":["! pip install langdetect\n","from langdetect import detect\n","\n","input_article= input(\"Please enter an article : \")\n","\n","detection=detect(input_article)\n","\n","if detection==\"en\":\n","      paragraph=input_article\n","      print(input_article)\n","      \n","elif detection==\"ru\":\n","      output=[]\n","      a=input_article.split(\".\")\n","      for i in a:\n","        if len(i)<=512:\n","            z= translator_ru_en(i, max_length=100000)\n","            for x in z:\n","                x['translation_text']=x['translation_text'].replace(\".\",\"\")\n","                output.append(x['translation_text'])\n","\n","        else:\n","            y=split_string(i)\n","            output1=\"\"\n","            for x in y:\n","              b=translator_ru_en(x, max_length=1000000)\n","              for x in b:\n","                   x['translation_text']=x['translation_text'].replace(\".\",\"\")\n","                   output1= output1+\" \"+x['translation_text']\n","            output.append(output1)\n","      output.pop()\n","      paragraph=\"\"\n","      for x in output:\n","        paragraph= paragraph+ x +\". \"\n","      print(paragraph)\n","  \n","elif detection==\"tr\":\n","      output=[]\n","      a=input_article.split(\".\")\n","      for i in a:\n","        if len(i)<=512:\n","            z= translator_tr_en(i, max_length=1000000)\n","            for x in z:\n","                 x['translation_text']=x['translation_text'].replace(\".\",\"\")\n","                 output.append(x['translation_text'])\n"," \n","        else:\n","            y=split_string(i)\n","            output1=\"\"\n","            for x in y:\n","               b=translator_tr_en(x, max_length=100000)\n","               for x in b:\n","                      x['translation_text']=x['translation_text'].replace(\".\",\"\")\n","                      output1= output1+\" \"+x['translation_text']\n","            output.append(output1)\n","      output.pop()\n","      paragraph=\"\"\n","      for x in output:\n","        paragraph= paragraph+ x +\". \"\n","      print(paragraph)\n","\n","else:\n","      print(\"unsupported\")\n","\n"],"execution_count":null,"outputs":[]}]}