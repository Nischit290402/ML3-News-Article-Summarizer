{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Heading.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPCiAuguXAqLj2j7JsRS1m2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ef981b41ae91467fa0acb614ba9fcbbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_be64062296bd49f183b10dc8e645fec2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e2ba6d00fd064b969818b6aaa58c03bf","IPY_MODEL_1f545a0dd522424a8ec47b0a436653b3"]}},"be64062296bd49f183b10dc8e645fec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2ba6d00fd064b969818b6aaa58c03bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_959cd633104d40bfab3e274744ac6c29","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0979438aed3040ccb2c347a76ee2aada"}},"1f545a0dd522424a8ec47b0a436653b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b41fc7e45eb04e7a943f935d6c3fc32a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5/? [00:02&lt;00:00,  1.68 tables/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f0cec176c2242d9993478461cbc2a3e"}},"959cd633104d40bfab3e274744ac6c29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0979438aed3040ccb2c347a76ee2aada":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b41fc7e45eb04e7a943f935d6c3fc32a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4f0cec176c2242d9993478461cbc2a3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db18a3ef520f44e983ce49014b1a3dd7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cb20849ce0004de4832eeb9e09284990","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4a5f7ee74f6e498e99ea82bd8e9234e9","IPY_MODEL_aff018bf96eb42689596975cf760ab7a"]}},"cb20849ce0004de4832eeb9e09284990":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a5f7ee74f6e498e99ea82bd8e9234e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_219cb81b71ad42408ddda6ae7fd15c00","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":2170,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2170,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b65048ca674e45ebb422035ae9e6a21c"}},"aff018bf96eb42689596975cf760ab7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef26673baae2418e8116fb5bf869b3c8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.61k/? [00:00&lt;00:00, 19.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f44b9aa34af4b629751a88e25fab9c0"}},"219cb81b71ad42408ddda6ae7fd15c00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b65048ca674e45ebb422035ae9e6a21c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef26673baae2418e8116fb5bf869b3c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5f44b9aa34af4b629751a88e25fab9c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a83ddf7b9df14ee486276fb4571305b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a2a72b6cd3544bf6afe3968bf0c12698","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b695ce0deaab470697a658b350fce3e0","IPY_MODEL_b9025da1ddbd44209e15aaf36418edf9"]}},"a2a72b6cd3544bf6afe3968bf0c12698":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b695ce0deaab470697a658b350fce3e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2bd028e700db4dc5902eec854b552654","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1199,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1199,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ae76edec4264e3482e1bbd070d65268"}},"b9025da1ddbd44209e15aaf36418edf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_afa5a483bdb044df9f7ccf2dfb806f55","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20k/1.20k [00:39&lt;00:00, 30.0B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cb7d89d3651a4885955a0a861390b1ed"}},"2bd028e700db4dc5902eec854b552654":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2ae76edec4264e3482e1bbd070d65268":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afa5a483bdb044df9f7ccf2dfb806f55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cb7d89d3651a4885955a0a861390b1ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b51fb97ea30409fa138722eefcb8411":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_760c45ce836e4c5c8bfd51010d48e150","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a6eb0f6f17734d11ade64a5147158a3c","IPY_MODEL_b187f952c9bc4c0ea54408c136d3d58b"]}},"760c45ce836e4c5c8bfd51010d48e150":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a6eb0f6f17734d11ade64a5147158a3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1f4344ae7ccd44c294d11f0b7b3c88f8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":791656,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":791656,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_442838a3b5a644d1bf26d78ac403eeee"}},"b187f952c9bc4c0ea54408c136d3d58b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b6618842d6fd4685a3f9b26c674dfe43","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 792k/792k [00:00&lt;00:00, 926kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e24d4efd39b443a9bea5b8112b1bfd10"}},"1f4344ae7ccd44c294d11f0b7b3c88f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"442838a3b5a644d1bf26d78ac403eeee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b6618842d6fd4685a3f9b26c674dfe43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e24d4efd39b443a9bea5b8112b1bfd10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8460df30659f43c1a5da0c3832a52f20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_319571a67207471e9ee67823c2d10b2e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_30ed1760acd9478384a6aabc3aa7216d","IPY_MODEL_af02d8582c4d4bb8879b4545193f5095"]}},"319571a67207471e9ee67823c2d10b2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30ed1760acd9478384a6aabc3aa7216d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d2cd187220924ca285c7d06f3b334629","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1389353,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1389353,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3050e015dd5a40b586d6865148aefc6f"}},"af02d8582c4d4bb8879b4545193f5095":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eec24f1a0b4b42c196f517914ad9f256","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.39M/1.39M [00:13&lt;00:00, 101kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1992954531ce46688b6ec26d378585ab"}},"d2cd187220924ca285c7d06f3b334629":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3050e015dd5a40b586d6865148aefc6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eec24f1a0b4b42c196f517914ad9f256":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1992954531ce46688b6ec26d378585ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c76f538bcf94e1297968e54345a23d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_88c991fb6f414143ae935cd6bc868fdc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fe5ef3aad8544615bf2966cfbbceafc1","IPY_MODEL_6cfd6f4ddd364ef2810f1dcb0d4430c0"]}},"88c991fb6f414143ae935cd6bc868fdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe5ef3aad8544615bf2966cfbbceafc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b241a0a64a734d679b63db3b6f7037fb","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_507abbfa2ba24878bad88e83aefe3a6c"}},"6cfd6f4ddd364ef2810f1dcb0d4430c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a2dcde9112a945a0afb629f679fe1f80","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [01:49&lt;00:00,  2.19s/ba]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f56e921d85e1465cab50d31a8a384ee6"}},"b241a0a64a734d679b63db3b6f7037fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"507abbfa2ba24878bad88e83aefe3a6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2dcde9112a945a0afb629f679fe1f80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f56e921d85e1465cab50d31a8a384ee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc9509ce1f714053a74475541da1e967":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4d19e89fd0b4fbfaf9567c2a1ad9bf5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_41e595424144425f974126ea5e8df51c","IPY_MODEL_c7c684c017c84b82b0177dae166c6de6"]}},"a4d19e89fd0b4fbfaf9567c2a1ad9bf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41e595424144425f974126ea5e8df51c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_43c8594a0fcd42e88bbd99df6471ffd2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":891691430,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":891691430,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac64a93a48b447ce8ba7456b305baa87"}},"c7c684c017c84b82b0177dae166c6de6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_83894a84fb0f4983b6c0790ac56827f4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 892M/892M [00:17&lt;00:00, 51.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b7ee67027a94c5eb8adc617a441a3dc"}},"43c8594a0fcd42e88bbd99df6471ffd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac64a93a48b447ce8ba7456b305baa87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83894a84fb0f4983b6c0790ac56827f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2b7ee67027a94c5eb8adc617a441a3dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRKPLmbhOfF-","executionInfo":{"status":"ok","timestamp":1626258183165,"user_tz":-330,"elapsed":19211,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"c0460a5e-6ac6-483c-9c06-ef0c8a1f759e"},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWgxaGzVPVGu","executionInfo":{"status":"ok","timestamp":1626258200040,"user_tz":-330,"elapsed":11520,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"36af9fb8-a7ac-4370-829f-7410b47e97ed"},"source":["! pip install datasets transformers rouge-score nltk\n","\n","import transformers\n","\n","model_checkpoint = \"t5-base\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/27/9c91ddee87b06d2de12f134c5171a49890427e398389f07f6463485723c3/datasets-1.9.0-py3-none-any.whl (262kB)\n","\u001b[K     |████████████████████████████████| 266kB 7.3MB/s \n","\u001b[?25hCollecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 12.9MB/s \n","\u001b[?25hCollecting rouge-score\n","  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting huggingface-hub<0.1.0\n","  Downloading https://files.pythonhosted.org/packages/35/03/071adc023c0a7e540cf4652fa9cad13ab32e6ae469bf0cc0262045244812/huggingface_hub-0.0.13-py3-none-any.whl\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Collecting fsspec>=2021.05.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/e1/7111d8afc76ee3171f4f99592cd29bac9d233ae1aa34623011506f955434/fsspec-2021.7.0-py3-none-any.whl (118kB)\n","\u001b[K     |████████████████████████████████| 122kB 51.0MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 44.8MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 45.4MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 35.9MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","\u001b[31mERROR: transformers 4.8.2 has requirement huggingface-hub==0.0.12, but you'll have huggingface-hub 0.0.13 which is incompatible.\u001b[0m\n","Installing collected packages: huggingface-hub, fsspec, xxhash, datasets, tokenizers, sacremoses, transformers, rouge-score\n","Successfully installed datasets-1.9.0 fsspec-2021.7.0 huggingface-hub-0.0.13 rouge-score-0.0.4 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2 xxhash-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139,"referenced_widgets":["ef981b41ae91467fa0acb614ba9fcbbd","be64062296bd49f183b10dc8e645fec2","e2ba6d00fd064b969818b6aaa58c03bf","1f545a0dd522424a8ec47b0a436653b3","959cd633104d40bfab3e274744ac6c29","0979438aed3040ccb2c347a76ee2aada","b41fc7e45eb04e7a943f935d6c3fc32a","4f0cec176c2242d9993478461cbc2a3e","db18a3ef520f44e983ce49014b1a3dd7","cb20849ce0004de4832eeb9e09284990","4a5f7ee74f6e498e99ea82bd8e9234e9","aff018bf96eb42689596975cf760ab7a","219cb81b71ad42408ddda6ae7fd15c00","b65048ca674e45ebb422035ae9e6a21c","ef26673baae2418e8116fb5bf869b3c8","5f44b9aa34af4b629751a88e25fab9c0"]},"id":"hr4BGkN1P7hD","executionInfo":{"status":"ok","timestamp":1626258214990,"user_tz":-330,"elapsed":13514,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"cec69659-adf6-4efc-f5bd-6816afb1930b"},"source":["from datasets import load_dataset, load_metric\n","\n","raw_datasets = load_dataset('csv', data_files= '/content/drive/MyDrive/articles1.csv')\n","metric = load_metric(\"rouge\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using custom data configuration default-bf79a20a2dfac1d3\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-bf79a20a2dfac1d3/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef981b41ae91467fa0acb614ba9fcbbd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-bf79a20a2dfac1d3/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23. Subsequent calls will reuse this data.\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db18a3ef520f44e983ce49014b1a3dd7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2170.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272,"referenced_widgets":["a83ddf7b9df14ee486276fb4571305b5","a2a72b6cd3544bf6afe3968bf0c12698","b695ce0deaab470697a658b350fce3e0","b9025da1ddbd44209e15aaf36418edf9","2bd028e700db4dc5902eec854b552654","2ae76edec4264e3482e1bbd070d65268","afa5a483bdb044df9f7ccf2dfb806f55","cb7d89d3651a4885955a0a861390b1ed","7b51fb97ea30409fa138722eefcb8411","760c45ce836e4c5c8bfd51010d48e150","a6eb0f6f17734d11ade64a5147158a3c","b187f952c9bc4c0ea54408c136d3d58b","1f4344ae7ccd44c294d11f0b7b3c88f8","442838a3b5a644d1bf26d78ac403eeee","b6618842d6fd4685a3f9b26c674dfe43","e24d4efd39b443a9bea5b8112b1bfd10","8460df30659f43c1a5da0c3832a52f20","319571a67207471e9ee67823c2d10b2e","30ed1760acd9478384a6aabc3aa7216d","af02d8582c4d4bb8879b4545193f5095","d2cd187220924ca285c7d06f3b334629","3050e015dd5a40b586d6865148aefc6f","eec24f1a0b4b42c196f517914ad9f256","1992954531ce46688b6ec26d378585ab"]},"id":"2rRMBoMzYNi-","executionInfo":{"status":"ok","timestamp":1626258224946,"user_tz":-330,"elapsed":7005,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"9513ac69-233e-4ae5-c2d1-166d553c0de8"},"source":["!pip install sentencepiece\n","\n","from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 7.6MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a83ddf7b9df14ee486276fb4571305b5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b51fb97ea30409fa138722eefcb8411","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8460df30659f43c1a5da0c3832a52f20","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1l0pCduxYVM2"},"source":["if model_checkpoint in [\"t5-base\"]:\n","    prefix = \"heading: \"\n","else:\n","    prefix = \"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fozkl0_zYdx8"},"source":["max_input_length = 256\n","max_target_length = 64\n","\n","def preprocess_function(examples):\n","    inputs = [prefix + doc for doc in examples[\"content\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"title\"], max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["9c76f538bcf94e1297968e54345a23d8","88c991fb6f414143ae935cd6bc868fdc","fe5ef3aad8544615bf2966cfbbceafc1","6cfd6f4ddd364ef2810f1dcb0d4430c0","b241a0a64a734d679b63db3b6f7037fb","507abbfa2ba24878bad88e83aefe3a6c","a2dcde9112a945a0afb629f679fe1f80","f56e921d85e1465cab50d31a8a384ee6"]},"id":"m0mzg61WaIm7","executionInfo":{"status":"ok","timestamp":1626258330564,"user_tz":-330,"elapsed":96440,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"5b59c358-0223-42ae-f7a0-7079646571f0"},"source":["tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c76f538bcf94e1297968e54345a23d8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wuR6wrAuaK5z","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["dc9509ce1f714053a74475541da1e967","a4d19e89fd0b4fbfaf9567c2a1ad9bf5","41e595424144425f974126ea5e8df51c","c7c684c017c84b82b0177dae166c6de6","43c8594a0fcd42e88bbd99df6471ffd2","ac64a93a48b447ce8ba7456b305baa87","83894a84fb0f4983b6c0790ac56827f4","2b7ee67027a94c5eb8adc617a441a3dc"]},"executionInfo":{"status":"ok","timestamp":1626258365350,"user_tz":-330,"elapsed":22170,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"e1184821-2020-4fb2-f194-05847d913af8"},"source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc9509ce1f714053a74475541da1e967","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tb142f1LaOZy"},"source":["batch_size = 16\n","args = Seq2SeqTrainingArguments(\n","    \"heading-generation\",\n","    learning_rate=10e-5,\n","    per_device_train_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    predict_with_generate=True,\n","    fp16=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZIBRs1gaYpi"},"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWPwyddqaemb"},"source":["import nltk\n","import numpy as np\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    \n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    # Extract a few results\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    \n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssJtCmu4ahBD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626258457892,"user_tz":-330,"elapsed":12037,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"30263441-70fd-4e47-f9bc-7bf6e4557440"},"source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using amp fp16 backend\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"k9XRk-sSakke","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1626263303993,"user_tz":-330,"elapsed":4837973,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"0360a49e-dbcd-4c0b-e18f-01f1c2bd0de5"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: publication, date, month, content, title, url, author, year, id, Unnamed: 0.\n","***** Running training *****\n","  Num examples = 50000\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 9375\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='9375' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9375/9375 1:20:36, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.134400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>nan</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>nan</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-500\n","Configuration saved in heading-generation/checkpoint-500/config.json\n","Model weights saved in heading-generation/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-1000\n","Configuration saved in heading-generation/checkpoint-1000/config.json\n","Model weights saved in heading-generation/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-1000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-1000/spiece.model\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-1500\n","Configuration saved in heading-generation/checkpoint-1500/config.json\n","Model weights saved in heading-generation/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-1500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-1500/spiece.model\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-2000\n","Configuration saved in heading-generation/checkpoint-2000/config.json\n","Model weights saved in heading-generation/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-2000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-2000/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-2500\n","Configuration saved in heading-generation/checkpoint-2500/config.json\n","Model weights saved in heading-generation/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-2500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-2500/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-1000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-3000\n","Configuration saved in heading-generation/checkpoint-3000/config.json\n","Model weights saved in heading-generation/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-3000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-3000/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-1500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-3500\n","Configuration saved in heading-generation/checkpoint-3500/config.json\n","Model weights saved in heading-generation/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-3500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-3500/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-2000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-4000\n","Configuration saved in heading-generation/checkpoint-4000/config.json\n","Model weights saved in heading-generation/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-4000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-4000/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-2500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-4500\n","Configuration saved in heading-generation/checkpoint-4500/config.json\n","Model weights saved in heading-generation/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-4500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-4500/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-3000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-5000\n","Configuration saved in heading-generation/checkpoint-5000/config.json\n","Model weights saved in heading-generation/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-5000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-5000/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-3500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-5500\n","Configuration saved in heading-generation/checkpoint-5500/config.json\n","Model weights saved in heading-generation/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-5500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-5500/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-4000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-6000\n","Configuration saved in heading-generation/checkpoint-6000/config.json\n","Model weights saved in heading-generation/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-6000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-6000/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-4500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-6500\n","Configuration saved in heading-generation/checkpoint-6500/config.json\n","Model weights saved in heading-generation/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-6500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-6500/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-5000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-7000\n","Configuration saved in heading-generation/checkpoint-7000/config.json\n","Model weights saved in heading-generation/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-7000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-7000/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-5500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-7500\n","Configuration saved in heading-generation/checkpoint-7500/config.json\n","Model weights saved in heading-generation/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-7500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-7500/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-6000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-8000\n","Configuration saved in heading-generation/checkpoint-8000/config.json\n","Model weights saved in heading-generation/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-8000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-8000/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-6500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-8500\n","Configuration saved in heading-generation/checkpoint-8500/config.json\n","Model weights saved in heading-generation/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-8500/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-8500/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-7000] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","Saving model checkpoint to heading-generation/checkpoint-9000\n","Configuration saved in heading-generation/checkpoint-9000/config.json\n","Model weights saved in heading-generation/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in heading-generation/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in heading-generation/checkpoint-9000/special_tokens_map.json\n","Copy vocab file to heading-generation/checkpoint-9000/spiece.model\n","Deleting older checkpoint [heading-generation/checkpoint-7500] due to args.save_total_limit\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1299: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=9375, training_loss=nan, metrics={'train_runtime': 4837.4325, 'train_samples_per_second': 31.008, 'train_steps_per_second': 1.938, 'total_flos': 5.872728254445158e+16, 'train_loss': nan, 'epoch': 3.0})"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9wC-vkc2UJl","executionInfo":{"status":"ok","timestamp":1626263401294,"user_tz":-330,"elapsed":3802,"user":{"displayName":"Siddartha Chennareddy","photoUrl":"","userId":"05578587641916586628"}},"outputId":"eac4b6c7-1945-435c-d381-87fb8ef89eb2"},"source":["model.save_pretrained(\"/content/drive/My Drive/Heading\")\n","tokenizer.save_pretrained(\"/content/drive/My Drive/Heading\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Configuration saved in /content/drive/My Drive/Heading/config.json\n","Model weights saved in /content/drive/My Drive/Heading/pytorch_model.bin\n","tokenizer config file saved in /content/drive/My Drive/Heading/tokenizer_config.json\n","Special tokens file saved in /content/drive/My Drive/Heading/special_tokens_map.json\n","Copy vocab file to /content/drive/My Drive/Heading/spiece.model\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/Heading/tokenizer_config.json',\n"," '/content/drive/My Drive/Heading/special_tokens_map.json',\n"," '/content/drive/My Drive/Heading/spiece.model',\n"," '/content/drive/My Drive/Heading/added_tokens.json',\n"," '/content/drive/My Drive/Heading/tokenizer.json')"]},"metadata":{"tags":[]},"execution_count":18}]}]}